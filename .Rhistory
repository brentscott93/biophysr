theme(legend.position = "none",
axis.text.y = element_text(size = 12),
axis.text.x = element_text(size = 12),
axis.title.x = element_text(size = 12))+
coord_flip()
vmax_plot
2*vmax_dat$error
vmax_dat$Estimate + 2*vmax_dat$error
all_fit
vmax_dat$Estimate - 2*vmax_dat$error
tidy(m1)
m1_coef <- tidy(m1) %>%
mutate(Run = 1)
m2_coef <- tidy(m2) %>%
mutate(Run = 2)
params <- rbind(m1_coef, m2_coef) %>%
dplyr::filter(rowname == "Asym")
params <- rbind(m1_coef, m2_coef) %>%
dplyr::filter(term == "Asym")
print(params)
S.alba.LL.4.1 <- drm(DryMatter~Dose, Herbicide, data=S.alba, fct = LL.4(),
pmodels=list(~Herbicide-1, ~1, ~1, ~Herbicide-1))
source('~/.active-rstudio-document', echo=TRUE)
summary(S.alba.LL.4.1)
S.alba.LL.4.1 <- drm(DryMatter~Dose,  data=S.alba, fct = LL.4(),
pmodels=list(~Herbicide-1, ~1, ~1, ~Herbicide-1))
S.alba.LL.4.1 <- drm(DryMatter~Dose,  data=S.alba, fct = LL.4(),
pmodels=list(~Herbicide-1, ~1, ~1, ~Herbicide-1))
S.alba
head(S.alba)
S.alba.LL.4.1 <- drm(DryMatter~Dose, Herbicide, data=S.alba, fct = LL.4(),
pmodels=list(~Herbicide-1, ~1, ~1, ~Herbicide-1))
summary(S.alba.LL.4.1)
tidy(S.alba.LL.4.1)
compParm(S.alba.LL.4.1, operator = "-")
compParm(S.alba.LL.4.1, operator = "-")
?comParm
?compParm
compParm(S.alba.LL.4.1, strValue = "b", operator = "-")
summary(S.alba.LL.4.1)
compParm(S.alba.LL.4.1, strValue = "e", operator = "-")
S.alba.LL.4.1 <- drm(DryMatter~Dose, Herbicide, data=S.alba, fct = LL.4(names = c("b", "lower", "upper", "ed50")),
pmodels=list(~Herbicide-1, ~1, ~1, ~Herbicide-1))
summary(S.alba.LL.4.1)
compParm(S.alba.LL.4.1, strValue = "ed50", operator = "-")
# Fitting a model with names assigned to the parameters!
spinach.m1 <- drm(SLOPE~DOSE, CURVE, data = spinach,
fct = LL.4(names = c("b", "lower", "upper", "ed50")))
summary(spinach.m1)
head(spinach)
plot(spinach)
## Calculating ratios of parameter estimates for the parameter named "ed50"
compParm(spinach.m1, "ed50")
## Calculating differences between parameter estimates for the parameter named "ed50"
compParm(spinach.m1, "ed50", "-")
## Calculating differences between parameter estimates for the parameter named "ed50"
w <- compParm(spinach.m1, "ed50", "-")
plot(w)
w
?compParm
ci_1 <- confint_tidy(m1, conf.level = 0.95)
ci_1
ci_1 <- confint_tidy(m1, conf.level = 0.95) %>% mutate(estimate = m1_coef$term)
all_1 <- full_join(m1_coef, ci_1)
library(shinyWidgets)
shinyWidgetsGallery()
?switchInput
hm_control <- "Yes"
rand_start <- if(hm_emcontrol == "Yes"){
TRUE
} else {
FALSE
}
hm_emcontrol <- "Yes"
rand_start <- if(hm_emcontrol == "Yes"){
TRUE
} else {
FALSE
}
library(biophysr)
app()
library(biophysr)
app()
app()
trap_selected_date <- "/Users/brentscott/Box Sync/Muscle Biophysics Lab/Data/biophysr/bscott/trap/project_myoV/myoV-S217A_pH7.0_15mM-Pi/031320"
trap_selected_conditions <- "myoV-S217A_pH7.0_15mM-Pi"
mv2nm <- 38
nm2pn <- 0.033
overlay_color = "red"
file_type = "csv"
hm_emcontrol = TRUE
observation_folders <- list_dir(trap_selected_date) %>%
dplyr::filter(str_detect(name, "obs")) %>%
pull(name)
grouped4r_files <- list_dir(trap_selected_date, recursive = TRUE) %>%
dplyr::filter(str_detect(name, "grouped")) %>%
pull(path)
directions <- list_dir(trap_selected_date) %>%
dplyr::filter(name == "directions.csv") %>%
pull(path)
if(file_type == "csv"){
read_directions <- suppressMessages(read_csv(directions)) %>%
mutate(folder = observation_folders,
grouped_file = grouped4r_files,
condition = trap_selected_conditions)%>%
filter(include == "yes")
} else {
read_directions <- suppressMessages(read_csv(directions)) %>%
mutate(folder = observation_folders,
grouped_file = grouped4r_files) %>%
filter(include == "yes")
}
read_directions$baseline_start_sec <- as.numeric(read_directions$baseline_start_sec)
read_directions$baseline_start_sec <- read_directions$baseline_start_sec*5000
read_directions$baseline_stop_sec <- as.numeric(read_directions$baseline_stop_sec)
read_directions$baseline_stop_sec <- read_directions$baseline_stop_sec*5000
#create results folders for output on dropbox
results_folder <- paste0(trap_selected_date, "/results")
dir.create(results_folder)
#create results folders for output on dropbox
results_folder <- paste0(trap_selected_date, "/results")
dir.create(results_folder)
events_folder <- paste0(trap_selected_date, "/results/events")
dir.create(events_folder)
plots_folder <- paste0(trap_selected_date, "/results/plots")
dir.create(plots_folder)
model_folder <- paste0(trap_selected_date, "/results/model_summary")
dir.create(model_folder)
source('~/Documents/UMASS/Lab/R/biophysr_package/biophysr/R/shiny_hidden_markov_analysis.R', echo=TRUE)
hmm_initial_parameters <- c(0.98, 0.02,        #Initial state probabilities
0.98, 0.02,         #transition probs s1 to s1/s2. These are guesses knowing they are stable states
0.02, 0.98)       #transition probs s2 to s1/s2. Again a guess
dir.create(plots_folder)
model_folder <- paste0(trap_selected_date, "/results/model_summary")
dir.create(model_folder)
hmm_initial_parameters <- c(0.98, 0.02,        #Initial state probabilities
0.98, 0.02,         #transition probs s1 to s1/s2. These are guesses knowing they are stable states
0.02, 0.98)       #transition probs s2 to s1/s2. Again a guess
## LOAD IN DATA ##
report <- vector("list")
var_signal_to_noise <- vector("list")
error_file <- file(paste0(trap_selected_date, "/error_log.txt"), open = "a")
var_signal_to_noise_directions <- vector("list")
folder <- 1
dat <-  if(file_type == "txt"){
#Load data and convert mV to nm
read_tsv(read_directions$grouped_file[[folder]], col_names = c("bead", "trap"))%>%
mutate(nm_converted = bead*mv2nm) %>%
dplyr::pull(nm_converted)
} else if(file_type == "csv") {
#Load data and convert mV to nm
read_csv(read_directions$grouped_file[[folder]]) %>%
mutate(nm_converted = bead*mv2nm) %>%
dplyr::pull(nm_converted)
}
processed_data <- if(read_directions$detrend[[folder]] == "yes"){
break_pts <- seq(25000, length(dat), by = 25000)
pracma::detrend(dat, tt = "linear", bp = break_pts)
} else if(read_directions$detrend[[folder]] == "no"){
get_mean <- mean(dat[read_directions$baseline_start_sec[[folder]] : read_directions$baseline_stop_sec[[folder]]])
dat - get_mean
}
run_mean <- running(processed_data, fun = mean, width = 150, by = 75)
run_var <- running(processed_data, fun = var, width = 150, by = 75)
running_table <- tibble(run_mean = run_mean,
run_var = run_var)
seed <- floor(runif(1, 0, 1e6))
hmm <- depmixS4::depmix(list(run_var~1,
run_mean~1),
data = running_table,
nstates = 2,
family = list(gaussian(),
gaussian()))
sd_run_mean <- sd(run_mean)
mean_run_var <- mean(run_var)
sd_run_var <- sd(run_var)
estimate_hmm_gaussians <- c(mean_run_var, sd_run_var, 0, sd_run_mean,
mean_run_var/2, sd_run_var/2, 3, sd_run_mean)     #s2
hmm <- setpars(hmm, c(hmm_initial_parameters, estimate_hmm_gaussians))
set.seed(seed)
hmm_fit <- depmixS4::fit(hmm, emcontrol = em.control(random.start = hm_emcontrol))
hmm_posterior <- depmixS4::posterior(hmm_fit)
hmm_repeat <- 0
while(hmm_repeat < 10){
if(hmm_posterior$state[[1]] == 1){
writeLines("HMM starts in state 1")
hmm_repeat <- 11
} else if(hmm_posterior$state[[1]] == 2){
writeLines(paste("Refitting HMM", hmm_repeat))
seed <- floor(runif(1, 0, 1e6))
set.seed(seed)
hmm_fit <- depmixS4::fit(hmm, emcontrol = em.control(random.start = FALSE))
hmm_posterior <- depmixS4::posterior(hmm_fit)
hmm_repeat <- hmm_repeat + 1
}
}
hmm_file <- file(paste0(trap_selected_date,
"/results/model_summary/",
read_directions$condition[[folder]],
"_",
read_directions$folder[[folder]],
"_",
"model.txt"),
open =  "a")
capture.output(depmixS4::summary(hmm_fit), file = hmm_file)
close(hmm_file)
sum_fit <- depmixS4::summary(hmm_fit)
base_var <- sum_fit[[1]]
event_var <- sum_fit[[2]]
var_signal_to_noise[[folder]] <- base_var/event_var
var_signal_to_noise_directions[[folder]] <- paste0(read_directions$folder[[folder]], "!_", base_var/event_var)
counter <- matrix(table(paste0(head(hmm_posterior$state,-1),tail(hmm_posterior$state,-1))), nrow = 1)
dimnames(counter) <- list(c("#_transitions"),
c("1-1", "1-2", "2-1", "2-2"))
count_events <- as.data.frame(counter, row.names = "#_transitions", make.names = TRUE) %>%
mutate(condition = paste0( read_directions$condition[[folder]]))
#save running mean, var, & state for ensemble averaging & dygraph
hmm_identified_events <- tibble(run_mean = run_mean,
run_var = run_var,
state = hmm_posterior$state)
## MEASURE EVENTS ##
## Calculate conversion between window length and data points
#setup
conversion <- length(processed_data)/length(run_mean)
#convert running mean object to tibble
run_mean_tibble <- tibble::enframe(run_mean) %>%
mutate(index = time(run_mean))
#finds lengths of events in number of running windows
run_length_encoding <- rle(hmm_posterior$state)
#converting to a tibble
rle_object <- as_tibble(do.call("cbind", run_length_encoding))
#make a copy of data for time on analysis
rle_object_4_duration <- rle_object %>%
dplyr::filter(values == 2)
if(hmm_posterior$state[[length(hmm_posterior$state)]] == 2){
#make a copy of data for time off analysis
time_offs <- rle_object %>%
dplyr::filter(values == 1) %>%
tail(-1) %>% #this gets rid of the first state 1 when that begins with the start of the trace recording
# head(-1) %>% #this gets rid of the last state 1 that only ends because we stopped collecting
mutate(off_length_5kHz = lengths*conversion,
time_off_ms = (off_length_5kHz/5000)*1000)
} else {
#make a copy of data for time off analysis
time_offs <- rle_object %>%
dplyr::filter(values == 1) %>%
tail(-1) %>% #this gets rid of the first state 1 when that begins with the start of the trace recording
head(-1) %>% #this gets rid of the last state 1 that only ends because we stopped collecting
mutate(off_length_5kHz = lengths*conversion,
time_off_ms = (off_length_5kHz/5000)*1000)
}
#calculates the events durations
on_off_times <- rle_object_4_duration %>%
dplyr::mutate(n_event = 1:nrow(rle_object_4_duration),
length_5kHz = lengths*conversion,
time_on_ms = (length_5kHz/5000)*1000,
time_off_ms = c(NA, time_offs$time_off_ms)) %>%
dplyr::select(n_event,values, everything()) %>%
dplyr::rename("num_windows" = lengths,
"hmm_state" = values)
#If the rle_object's last row is in state 1, get rid of that last row. This needs to end in state 2 to capture the end of the last event
rle_object_4_step_sizes <- if(tail(rle_object, 1)$values == 1){
slice(rle_object, -length(rle_object$values))
} else {
rle_object
}
split_data <- rle_object_4_step_sizes %>%
dplyr::mutate(cumsum = cumsum(lengths)) %>%
dplyr::group_by(values) %>%
split(rle_object_4_step_sizes$values)
#data is recmombined in a state_1 column and a state_2
#the values in these columns represent the last data point (in window lengths) in either state 1 or state 2
#So the range of values between the end of state 1 (or start of state 2) and the end of state 2 is the event duration
regroup_data <- bind_cols(state_1_end = split_data[[1]]$cumsum, state_2_end = split_data[[2]]$cumsum)
#loop over regrouped data to find the mean of the events displacements
step_sizes <- vector("list", length = nrow(regroup_data)) #allocate space for output storage of loop
peak_nm_index <- vector()
#loop over regrouped data to find the mean of the events displacements
step_sizes <- vector("list", length = nrow(regroup_data)) #allocate space for output storage of loop
peak_nm_index <- vector()
for(i in 1:nrow(regroup_data)){
win_values_t <- run_mean_tibble[(regroup_data$state_1_end[i]+1) : (regroup_data$state_2_end[i]),]
max_step_index <- win_values_t$index[which.max(abs(win_values_t$value))]
peak_nm_index[i] <- max_step_index
step_sizes[[i]] <-   win_values_t$value[which(win_values_t$index == max_step_index)]
}
nrow(regroup_data)
i <- 1
win_values_t <- run_mean_tibble[(regroup_data$state_1_end[i]+1) : (regroup_data$state_2_end[i]),]
max_step_index <- win_values_t$index[which.max(abs(win_values_t$value))]
peak_nm_index[i] <- max_step_index
step_sizes[[i]] <-   win_values_t$value[which(win_values_t$index == max_step_index)]
regroup_data
win_values_t
win_values_t
run_mean_tibble
## MEASURE EVENTS ##
## Calculate conversion between window length and data points
#setup
conversion <- length(processed_data)/length(run_mean)
#convert running mean object to tibble
run_mean_tibble <- tibble::enframe(run_mean) %>%
mutate(index = time(run_mean))
View(run_mean_tibble)
run_mean_tibble
#convert running mean object to tibble
run_mean_tibble <- tibble::enframe(run_mean) %>%
mutate(index = time(run_mean))
run_mean_tibble
?enframe
#convert running mean object to tibble
run_mean_tibble <- tibble::enframe(unname(run_mean)) %>%
mutate(index = time(run_mean))
View(run_mean_tibble)
#convert running mean object to tibble
run_mean_tibble <- tibble::enframe(unname(run_mean)) %>%
mutate(index = time(run_mean))
run_mean_tibble
#convert running mean object to tibble
run_mean_tibble <- tibble::enframe(run_mean) %>%
mutate(index = seq(min(run_mean), max(run_mean), length.out = length(run_mean)))
run_mean_tibble
#convert running mean object to tibble
run_mean_tibble <- tibble::enframe(run_mean) %>%
mutate(index = seq(1, length(run_mean), length.out = length(run_mean)))
run_mean_tibble
View(run_mean_tibble)
#finds lengths of events in number of running windows
run_length_encoding <- rle(hmm_posterior$state)
#converting to a tibble
rle_object <- as_tibble(do.call("cbind", run_length_encoding))
#make a copy of data for time on analysis
rle_object_4_duration <- rle_object %>%
dplyr::filter(values == 2)
if(hmm_posterior$state[[length(hmm_posterior$state)]] == 2){
#make a copy of data for time off analysis
time_offs <- rle_object %>%
dplyr::filter(values == 1) %>%
tail(-1) %>% #this gets rid of the first state 1 when that begins with the start of the trace recording
# head(-1) %>% #this gets rid of the last state 1 that only ends because we stopped collecting
mutate(off_length_5kHz = lengths*conversion,
time_off_ms = (off_length_5kHz/5000)*1000)
} else {
#make a copy of data for time off analysis
time_offs <- rle_object %>%
dplyr::filter(values == 1) %>%
tail(-1) %>% #this gets rid of the first state 1 when that begins with the start of the trace recording
head(-1) %>% #this gets rid of the last state 1 that only ends because we stopped collecting
mutate(off_length_5kHz = lengths*conversion,
time_off_ms = (off_length_5kHz/5000)*1000)
}
#calculates the events durations
on_off_times <- rle_object_4_duration %>%
dplyr::mutate(n_event = 1:nrow(rle_object_4_duration),
length_5kHz = lengths*conversion,
time_on_ms = (length_5kHz/5000)*1000,
time_off_ms = c(NA, time_offs$time_off_ms)) %>%
dplyr::select(n_event,values, everything()) %>%
dplyr::rename("num_windows" = lengths,
"hmm_state" = values)
#If the rle_object's last row is in state 1, get rid of that last row. This needs to end in state 2 to capture the end of the last event
rle_object_4_step_sizes <- if(tail(rle_object, 1)$values == 1){
slice(rle_object, -length(rle_object$values))
} else {
rle_object
}
split_data <- rle_object_4_step_sizes %>%
dplyr::mutate(cumsum = cumsum(lengths)) %>%
dplyr::group_by(values) %>%
split(rle_object_4_step_sizes$values)
#data is recmombined in a state_1 column and a state_2
#the values in these columns represent the last data point (in window lengths) in either state 1 or state 2
#So the range of values between the end of state 1 (or start of state 2) and the end of state 2 is the event duration
regroup_data <- bind_cols(state_1_end = split_data[[1]]$cumsum, state_2_end = split_data[[2]]$cumsum)
#loop over regrouped data to find the mean of the events displacements
step_sizes <- vector("list", length = nrow(regroup_data)) #allocate space for output storage of loop
peak_nm_index <- vector()
for(i in 1:nrow(regroup_data)){
win_values_t <- run_mean_tibble[(regroup_data$state_1_end[i]+1) : (regroup_data$state_2_end[i]),]
max_step_index <- win_values_t$index[which.max(abs(win_values_t$value))]
peak_nm_index[i] <- max_step_index
step_sizes[[i]] <-   win_values_t$value[which(win_values_t$index == max_step_index)]
}
minus1 <- split_data[[1]]$cumsum[-1]
minus2 <- split_data[[2]]$cumsum[-length(split_data[[2]]$cumsum)]
s1_regroup_data <- bind_cols(state_2_end = minus2, state_1_end = minus1)
#loop over s1_regrouped data to find the mean of state 1
state_1_avg <- vector("list", length = nrow(regroup_data)) #allocate space for output storage of loop
library(biophysr)
app()
app()
app()
library(biophysr)
app()
app()
app()
app()
trap_selected_date <- "/Users/brentscott/Box Sync/Muscle Biophysics Lab/Data/biophysr/bscott/trap/project_myoV/TEST_myoV-S217A_pH7.0_30mM-Pi"
trap_selected_conditions <- "myoV-S217A_pH7.0_30mM-Pi"
observation_folders <- list_dir(trap_selected_date) %>%
dplyr::filter(str_detect(name, "obs")) %>%
pull(name)
trap_selected_date <- "/Users/brentscott/Box Sync/Muscle Biophysics Lab/Data/biophysr/bscott/trap/project_myoV/TEST_myoV-S217A_pH7.0_30mM-Pi"
trap_selected_date <- "/Users/brentscott/Box Sync/Muscle Biophysics Lab/Data/biophysr/bscott/trap/project_myoV/TEST_myoV-S217A_pH7.0_30mM-Pi"
observation_folders <- list_dir(trap_selected_date) %>%
dplyr::filter(str_detect(name, "obs")) %>%
pull(name)
grouped4r_files <- list_dir(trap_selected_date, recursive = TRUE) %>%
dplyr::filter(str_detect(name, "grouped")) %>%
pull(path)
trap_selected_date <- "/Users/brentscott/Box Sync/Muscle Biophysics Lab/Data/biophysr/bscott/trap/project_myoV/TEST_myoV-S217A_pH7.0_30mM-Pi "
observation_folders <- list_dir(trap_selected_date) %>%
dplyr::filter(str_detect(name, "obs")) %>%
pull(name)
grouped4r_files <- list_dir(trap_selected_date, recursive = TRUE) %>%
dplyr::filter(str_detect(name, "grouped")) %>%
pull(path)
trap_selected_date <- "/Users/brentscott/Box Sync/Muscle Biophysics Lab/Data/biophysr/bscott/trap/project_myoV/TEST_myoV-S217A_pH7.0_30mM-Pi/022719"
trap_selected_date <- "/Users/brentscott/Box Sync/Muscle Biophysics Lab/Data/biophysr/bscott/trap/project_myoV/TEST_myoV-S217A_pH7.0_30mM-Pi/022719"
observation_folders <- list_dir(trap_selected_date) %>%
dplyr::filter(str_detect(name, "obs")) %>%
pull(name)
app()
trap_selected_date <- "/Users/brentscott/Box Sync/Muscle Biophysics Lab/Data/biophysr/bscott/trap/project_myoV/TEST_myoV-S217A_pH7.0_30mM-Pi/022719"
trap_selected_conditions <- "myoV-S217A_pH7.0_30mM-Pi"
nm2pn <- 0.04
overlay_color = "red"
file_type = "txt"
hm_emcontrol = FALSE
folder <- 1
observation_folders <- list_dir(trap_selected_date) %>%
dplyr::filter(str_detect(name, "obs")) %>%
pull(name)
grouped4r_files <- list_dir(trap_selected_date, recursive = TRUE) %>%
dplyr::filter(str_detect(name, "grouped")) %>%
pull(path)
directions <- list_dir(trap_selected_date) %>%
dplyr::filter(name == "directions.csv") %>%
pull(path)
if(file_type == "csv"){
read_directions <- suppressMessages(read_csv(directions)) %>%
mutate(folder = observation_folders,
grouped_file = grouped4r_files,
condition = trap_selected_conditions)%>%
filter(include == "yes")
} else {
read_directions <- suppressMessages(read_csv(directions)) %>%
mutate(folder = observation_folders,
grouped_file = grouped4r_files) %>%
filter(include == "yes")
}
read_directions$baseline_start_sec <- as.numeric(read_directions$baseline_start_sec)
read_directions$baseline_start_sec <- read_directions$baseline_start_sec*5000
read_directions$baseline_stop_sec <- as.numeric(read_directions$baseline_stop_sec)
read_directions$baseline_stop_sec <- read_directions$baseline_stop_sec*5000
#create results folders for output on dropbox
results_folder <- paste0(trap_selected_date, "/results")
dir.create(results_folder)
events_folder <- paste0(trap_selected_date, "/results/events")
dir.create(events_folder)
plots_folder <- paste0(trap_selected_date, "/results/plots")
dir.create(plots_folder)
model_folder <- paste0(trap_selected_date, "/results/model_summary")
dir.create(model_folder)
ensemble_folder <- paste0(trap_selected_date, "/results/ensemble")
dir.create(ensemble_folder)
hmm_initial_parameters <- c(0.98, 0.02,        #Initial state probabilities
0.98, 0.02,         #transition probs s1 to s1/s2. These are guesses knowing they are stable states
0.02, 0.98)       #transition probs s2 to s1/s2. Again a guess
## LOAD IN DATA ##
report <- vector("list")
var_signal_to_noise <- vector("list")
error_file <- file(paste0(trap_selected_date, "/error_log.txt"), open = "a")
var_signal_to_noise_directions <- vector("list")
report[[folder]] <- paste0("failed_to_initialize!_", read_directions$folder[[folder]])
dat <-  if(file_type == "txt"){
#Load data and convert mV to nm
read_tsv(read_directions$grouped_file[[folder]], col_names = c("bead", "trap"))%>%
mutate(nm_converted = bead*mv2nm) %>%
dplyr::pull(nm_converted)
} else if(file_type == "csv") {
#Load data and convert mV to nm
read_csv(read_directions$grouped_file[[folder]]) %>%
mutate(nm_converted = bead*mv2nm) %>%
dplyr::pull(nm_converted)
}
mv2nm <- 31
nm2pn <- 0.04
dat <-  if(file_type == "txt"){
#Load data and convert mV to nm
read_tsv(read_directions$grouped_file[[folder]], col_names = c("bead", "trap"))%>%
mutate(nm_converted = bead*mv2nm) %>%
dplyr::pull(nm_converted)
} else if(file_type == "csv") {
#Load data and convert mV to nm
read_csv(read_directions$grouped_file[[folder]]) %>%
mutate(nm_converted = bead*mv2nm) %>%
dplyr::pull(nm_converted)
}
processed_data <- if(read_directions$detrend[[folder]] == "yes"){
break_pts <- seq(25000, length(dat), by = 25000)
as.vector(pracma::detrend(dat, tt = "linear", bp = break_pts))
} else if(read_directions$detrend[[folder]] == "no"){
get_mean <- mean(dat[read_directions$baseline_start_sec[[folder]] : read_directions$baseline_stop_sec[[folder]]])
dat - get_mean
}
## RUNNING MEAN & VAR ##
w_width <- 150
run_mean <- running(processed_data, fun = mean, width = w_width, by = w_width/2)
run_var <- running(processed_data, fun = var, width = w_width, by = w_width/2)
running_table <- tibble(run_mean = run_mean,
run_var = run_var)
